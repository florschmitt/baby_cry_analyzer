{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fcc8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b1e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data_set'\n",
    "subfolders = ['awake', 'belly_pain', 'burping', 'discomfort', 'hug', 'hungry', 'tired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0d217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c650c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_emphasis_filter(signal, alpha=0.95):\n",
    "    return np.append(signal[0], signal[1:] - alpha * signal[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ac2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_extraction(file_path, n_mfcc=13):\n",
    "    # Load the audio file\n",
    "    signal, sr = librosa.load(file_path, sr=None)  # Corrected sr value\n",
    "\n",
    "    # Apply a pre-emphasis filter\n",
    "    filtered_signal = pre_emphasis_filter(signal)\n",
    "\n",
    "    # Frame the signal into short frames\n",
    "    frames = librosa.util.frame(filtered_signal, frame_length=int(sr*0.025), hop_length=int(sr*0.01))\n",
    "\n",
    "    # Compute the periodogram estimate of the power spectrum\n",
    "    power_spectra = np.abs(np.fft.rfft(frames, axis=0))**2\n",
    "\n",
    "    # Apply Mel filterbank\n",
    "    mel_filterbank = librosa.filters.mel(sr=sr, n_fft=int(sr*0.025), n_mels=n_mfcc)\n",
    "    mel_spectra = np.dot(mel_filterbank, power_spectra)\n",
    "\n",
    "    # Take the logarithm of filterbank energies\n",
    "    log_mel_spectra = np.log(mel_spectra + 1e-10)\n",
    "\n",
    "    # Apply DCT to get MFCCs\n",
    "    mfccs = librosa.feature.mfcc(S=log_mel_spectra, n_mfcc=n_mfcc)\n",
    "    \n",
    "    return mfccs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "060c67f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over the dataset folder and extracting features and labels\n",
    "for subfolder in subfolders:\n",
    "    for file_name in os.listdir(os.path.join(data_folder, subfolder)):\n",
    "        file_path = os.path.join(data_folder, subfolder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            # Extracting MFCCs from the audio file\n",
    "            mfccs = mfcc_extraction(file_path)\n",
    "            \n",
    "            # Averaging the MFCCs along time axis to get a fixed size feature vector\n",
    "            avg_mfccs = np.mean(mfccs, axis=0)\n",
    "            \n",
    "            features.append(avg_mfccs.tolist())\n",
    "            labels.append(subfolders.index(subfolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8270dbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.13525230e+01,  1.35064209e+00, -3.95582677e+00, ...,\n",
       "         1.74346233e-01, -3.64772285e-02, -1.89499866e-02],\n",
       "       [-4.79312340e+01, -3.83274778e+00, -1.66693799e+00, ...,\n",
       "        -8.72744631e-02,  8.56873313e-02, -8.51965237e-02],\n",
       "       [-3.11570621e+01,  6.16884815e-01, -2.16594136e+00, ...,\n",
       "         2.06079975e-01,  1.65666681e-01,  1.10005348e-01],\n",
       "       ...,\n",
       "       [-3.92472420e+01, -1.19090487e+00, -2.88384150e+00, ...,\n",
       "         1.23570621e-01, -4.13932814e-02, -3.46297232e-03],\n",
       "       [-3.98588625e+01, -2.81826615e+00, -2.49154098e+00, ...,\n",
       "        -2.05255757e-01, -8.62252933e-02,  4.27912240e-02],\n",
       "       [-6.68963651e+01, -4.42485595e+00,  1.65261553e+00, ...,\n",
       "        -5.82796237e-02,  6.71773864e-03, -1.49189896e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c2ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0b4b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "weights_dict = {class_label: weight for class_label, weight in zip(np.unique(y_train), class_weights)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef498cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 1.2307692307692308, 1: 10.0,\n",
       "                                     2: 8.88888888888889, 3: 0.6130268199233716,\n",
       "                                     4: 1.3114754098360655,\n",
       "                                     5: 0.3818615751789976,\n",
       "                                     6: 1.0389610389610389},\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={0: 1.2307692307692308, 1: 10.0,\n",
       "                                     2: 8.88888888888889, 3: 0.6130268199233716,\n",
       "                                     4: 1.3114754098360655,\n",
       "                                     5: 0.3818615751789976,\n",
       "                                     6: 1.0389610389610389},\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1.2307692307692308, 1: 10.0,\n",
       "                                     2: 8.88888888888889, 3: 0.6130268199233716,\n",
       "                                     4: 1.3114754098360655,\n",
       "                                     5: 0.3818615751789976,\n",
       "                                     6: 1.0389610389610389},\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier(n_estimators=100, class_weight=weights_dict, random_state=42)\n",
    "forest_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36e51e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6156583629893239\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       awake       0.33      0.27      0.30        26\n",
      "  belly_pain       1.00      0.50      0.67         4\n",
      "     burping       1.00      0.25      0.40         4\n",
      "  discomfort       0.76      0.53      0.62        64\n",
      "         hug       0.73      0.54      0.62        35\n",
      "      hungry       0.62      0.83      0.71       118\n",
      "       tired       0.44      0.40      0.42        30\n",
      "\n",
      "    accuracy                           0.62       281\n",
      "   macro avg       0.70      0.47      0.53       281\n",
      "weighted avg       0.63      0.62      0.60       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=subfolders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a526a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio_file(file_path, model):\n",
    "    try:\n",
    "        mfccs = mfcc_extraction(file_path)\n",
    "        avg_mfccs = np.mean(mfccs, axis=0).reshape(1, -1)\n",
    "        prediction = model.predict(avg_mfccs)\n",
    "        print(f\"File: {file_path} | Predicted category: {subfolders[prediction[0]]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Can't load file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72a1eb1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subfolder: awake\n",
      "File: a_p\\awake\\awake_0.wav | Predicted category: hungry\n",
      "File: a_p\\awake\\awake_130.wav | Predicted category: hungry\n",
      "File: a_p\\awake\\awake_16.wav | Predicted category: hungry\n",
      "File: a_p\\awake\\awake_83.wav | Predicted category: awake\n",
      "Processing subfolder: belly_pain\n",
      "File: a_p\\belly_pain\\549a46d8-9c84-430e-ade8-97eae2bef787-1430130772174-1.7-m-48-bp.wav | Predicted category: hungry\n",
      "File: a_p\\belly_pain\\BellyPain02.wav | Predicted category: hungry\n",
      "Processing subfolder: burping\n",
      "File: a_p\\burping\\7E4B9C14-F955-4BED-9B03-7F3096A6CBFF-1430540826-1.0-f-26-bu.wav | Predicted category: hungry\n",
      "File: a_p\\burping\\Burping-10.wav | Predicted category: hungry\n",
      "Processing subfolder: discomfort\n",
      "File: a_p\\discomfort\\2294E2B2-8E36-4DA6-A898-B947CB9446AB-1436462707-1.1-m-26-dc.wav | Predicted category: hungry\n",
      "File: a_p\\discomfort\\Cold_Hot09.wav | Predicted category: hungry\n",
      "File: a_p\\discomfort\\diaper_6.wav | Predicted category: discomfort\n",
      "File: a_p\\discomfort\\diaper_91.wav | Predicted category: discomfort\n",
      "File: a_p\\discomfort\\uncomfortable_151.wav | Predicted category: discomfort\n",
      "File: a_p\\discomfort\\uncomfortable_16.wav | Predicted category: discomfort\n",
      "Processing subfolder: hug\n",
      "File: a_p\\hug\\hug_128.wav | Predicted category: hungry\n",
      "File: a_p\\hug\\hug_156.wav | Predicted category: hug\n",
      "File: a_p\\hug\\hug_90.wav | Predicted category: hug\n",
      "Processing subfolder: hungry\n",
      "File: a_p\\hungry\\0c8f14a9-6999-485b-97a2-913c1cbf099c-1430760394426-1.7-m-26-hu.wav | Predicted category: hungry\n",
      "File: a_p\\hungry\\4cefc13c-e7c0-4b5a-bddb-c40c103e640a-1431583459308-1.7-f-26-hu.wav | Predicted category: hungry\n",
      "File: a_p\\hungry\\ae5a462b-5424-4b5b-82d5-07ccb61654ab-1430405436291-1.7-f-04-hu.wav | Predicted category: hungry\n",
      "File: a_p\\hungry\\hungry_18.wav | Predicted category: hungry\n",
      "File: a_p\\hungry\\hungry_39.wav | Predicted category: hungry\n",
      "Processing subfolder: tired\n",
      "File: a_p\\tired\\06c4cfa2-7fa6-4fda-91a1-ea186a4acc64-1430029237378-1.7-f-26-ti.wav | Predicted category: hungry\n",
      "File: a_p\\tired\\d6cda191-4962-4308-9a36-46d5648a95ed-1431587899682-1.7-m-04-ti.wav | Predicted category: awake\n",
      "File: a_p\\tired\\sleepy_63.wav | Predicted category: tired\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"a_p\"\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(folder_path, subfolder)\n",
    "    \n",
    "    if not os.path.exists(subfolder_path):\n",
    "        print(f\"Subfolder {subfolder_path} not found.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing subfolder: {subfolder}\")\n",
    "    \n",
    "    for new_file in os.listdir(subfolder_path):\n",
    "        file_path = os.path.join(subfolder_path, new_file)\n",
    "        predict_audio_file(file_path, forest_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
