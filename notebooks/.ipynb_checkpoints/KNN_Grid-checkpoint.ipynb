{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e585f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_emphasis_filter(signal, alpha=0.97):\n",
    "    return np.append(signal[0], signal[1:] - alpha * signal[:-1])\n",
    "\n",
    "def extract_mfcc(file_path, num_segments=10, n_mfcc=13, n_fft=2048, hop_length=512):\n",
    "    signal, sr = librosa.load(file_path, sr=22050)\n",
    "    signal = pre_emphasis_filter(signal)\n",
    "    \n",
    "    # Ensuring the number of segments is valid\n",
    "    num_samples_per_segment = int(len(signal) / num_segments)\n",
    "    if num_samples_per_segment == 0:\n",
    "        print(\"Warning: num_segments is too high. Lower the value.\")\n",
    "        return []\n",
    "    \n",
    "    hop_length = num_samples_per_segment // 2  # 50% overlap\n",
    "    mfccs = []\n",
    "    \n",
    "    for s in range(num_segments):\n",
    "        start_sample = num_samples_per_segment * s\n",
    "        end_sample = start_sample + num_samples_per_segment\n",
    "        \n",
    "        # Applying window function\n",
    "        window = np.hamming(num_samples_per_segment)\n",
    "        frame = signal[start_sample:end_sample] * window\n",
    "        \n",
    "        # Calculating MFCC\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=frame,\n",
    "            sr=sr,\n",
    "            n_mfcc=n_mfcc,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length\n",
    "        )\n",
    "        \n",
    "        # Flattening the MFCCs into a one-dimensional array\n",
    "        flat_mfcc = mfcc.T.flatten()\n",
    "        mfccs.append(flat_mfcc)\n",
    "    \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92990a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features(file_path, num_segments=10):\n",
    "#     signal, sr = librosa.load(file_path, sr=22050)\n",
    "#     num_samples_per_segment = int(len(signal) / num_segments)\n",
    "#     hop_length = num_samples_per_segment // 2  \n",
    "    \n",
    "#     mfccs = []\n",
    "#     chromas = []\n",
    "    \n",
    "#     for s in range(num_segments):\n",
    "#         start_sample = num_samples_per_segment * s\n",
    "#         end_sample = start_sample + num_samples_per_segment\n",
    "        \n",
    "#         # Extracting MFCC\n",
    "#         mfcc = librosa.feature.mfcc(\n",
    "#             y=signal[start_sample:end_sample],\n",
    "#             sr=sr,\n",
    "#             n_mfcc=13,\n",
    "#             n_fft=num_samples_per_segment,\n",
    "#             hop_length=hop_length\n",
    "#         ).T.flatten()\n",
    "        \n",
    "#         # Extracting Chroma\n",
    "#         chroma = librosa.feature.chroma_stft(\n",
    "#             y=signal[start_sample:end_sample],\n",
    "#             sr=sr,\n",
    "#             n_fft=num_samples_per_segment,\n",
    "#             hop_length=hop_length\n",
    "#         ).T.flatten()\n",
    "\n",
    "#         mfccs.append(mfcc)\n",
    "#         chromas.append(chroma)\n",
    "\n",
    "#     features = np.hstack((mfccs, chromas)) # Combine the features horizontally\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c15ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating the dataset loading and feature extraction\n",
    "data_folder = 'data_set' # replace with the actual folder path\n",
    "subfolders = os.listdir(data_folder)\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for subfolder in tqdm(subfolders, desc=\"Extracting features\"):\n",
    "    file_path = os.path.join(data_folder, subfolder)\n",
    "    for file_name in os.listdir(file_path):\n",
    "        if file_name.endswith('.wav'):\n",
    "            mfccs = extract_mfcc(os.path.join(file_path, file_name))\n",
    "            features.extend(mfccs)\n",
    "            labels.extend([subfolder] * len(mfccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c64e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_weights = compute_sample_weight(class_weight='balanced', y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1094fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': range(1, 11),\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': range(20,40,5), # Выбор оптимального размера листа может зависеть от вашего датасета\n",
    "    'p': [1, 2]  # Используется только, если 'metric' установлен в 'minkowski'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af092d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276687d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=param_grid, \n",
    "    cv=kf,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d665b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(scaled_features, labels)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ae952",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "errors = []\n",
    "\n",
    "for i in tqdm(range(10), desc=\"Classifying\"):\n",
    "    scores = cross_val_score(best_knn, scaled_features, labels, cv=kf)\n",
    "    accuracies.append(scores.mean())\n",
    "    errors.append(scores.std() * 2)\n",
    "    print(f\"Run {i+1}: Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64275e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "\n",
    "# loo = LeaveOneOut()\n",
    "# accuracies = []\n",
    "\n",
    "# for i in tqdm(range(10), desc=\"Classifying\"):\n",
    "#     scores = cross_val_score(best_knn, scaled_features, labels, cv=loo)\n",
    "#     accuracies.append(scores.mean())\n",
    "#     print(f\"Run {i+1}: Accuracy: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfbc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Разделение на обучающую и тестовую выборки\n",
    "# X_train, X_test, y_train, y_test = train_test_split(scaled_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Обучение модели на обучающей выборке\n",
    "# best_knn.fit(X_train, y_train)\n",
    "\n",
    "# # Оценка модели на тестовой выборке\n",
    "# accuracy = best_knn.score(X_test, y_test)\n",
    "# print(f\"Accuracy on test data: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19629aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Разделение на обучающую, валидационную и тестовую выборки\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(scaled_features, labels, test_size=0.4, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
